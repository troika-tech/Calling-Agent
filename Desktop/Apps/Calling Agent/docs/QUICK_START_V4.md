# Quick Start Guide - V4 Optimizations

## What's New in V4?

**ðŸš€ 40% Faster Response Times** - From 5 seconds to 3 seconds!

Three major optimizations:
1. âš¡ **GPT-4o-mini** - 2-3x faster LLM, 95% cost reduction
2. ðŸŽ¤ **Streaming TTS** - Audio plays as it's generated (sub-200ms TTFB)
3. ðŸ§  **Deepgram VAD** - Built-in voice activity detection (ready for streaming)

---

## Prerequisites

**No new dependencies needed!** All optimizations use existing packages.

**Required Environment Variables:**
```bash
DEEPGRAM_API_KEY=your_key    # For streaming TTS & VAD
OPENAI_API_KEY=your_key      # For GPT-4o-mini
```

---

## Configuration

### For New Agents

When creating agents, use these recommended settings:

```javascript
{
  "name": "Fast Support Agent",
  "config": {
    "prompt": "You are a helpful support agent...",
    "llm": {
      "model": "gpt-4o-mini",    // âš¡ FAST!
      "temperature": 0.7
      // No maxTokens - let system prompt control brevity naturally
    },
    "voice": {
      "provider": "deepgram",     // Required for streaming
      "voiceId": "aura-asteria-en"
    },
    "language": "en",
    "firstMessage": "Hi! How can I help you today?"
  }
}
```

### For Existing Agents

Update via API or frontend:

```bash
# Update agent to use optimizations
curl -X PUT http://localhost:5000/api/v1/agents/{agentId} \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "config": {
      "llm": { "model": "gpt-4o-mini" },
      "voice": { "provider": "deepgram", "voiceId": "aura-asteria-en" }
    }
  }'
```

---

## Testing

### 1. Start Backend
```bash
cd backend
npm run dev
```

### 2. Make a Test Call

Watch the logs for V4 markers:
```bash
# Terminal 1: Run backend with logs
npm run dev

# Terminal 2: Watch for optimization markers
tail -f logs/combined.log | grep "v4"
```

**Look for these markers:**
- `ðŸ”” SILENCE (v4) - VAD confirmed` âœ… VAD working
- `ðŸŽ¤ STREAMING TTS (v4)` âœ… Streaming TTS active
- `âœ… STREAMING TTS COMPLETE (v4)` âœ… Audio streamed

### 3. Verify Performance

Expected timeline for a typical interaction:
```
0ms:    User starts speaking
1000ms: User stops speaking
1150ms: ðŸ”” SILENCE (v4) - VAD confirmed (150ms detection)
1950ms: STT complete (800ms)
2950ms: LLM complete (1000ms with gpt-4o-mini)
3150ms: ðŸŽ¤ First audio chunk sent (200ms TTFB)
3200ms: User hears AI response

Total: ~3.2 seconds (was ~5 seconds in V3)
```

---

## Troubleshooting

### Deepgram VAD (Future Streaming Feature)

**Note:** V4 includes Deepgram VAD infrastructure for future streaming STT.
Currently using optimized time-based detection (150ms threshold).

**To enable streaming VAD (optional):**
1. Uncomment Deepgram live connection code in handler
2. Stream audio chunks directly to Deepgram
3. Use VAD events (`SpeechStarted`, `UtteranceEnd`) for processing

See `backend/src/services/deepgram.service.ts:createLiveConnectionWithVAD()`

### Streaming TTS Not Working

**Symptom:** No `ðŸŽ¤ STREAMING TTS (v4)` logs

**Check:**
1. Agent voice provider is `deepgram`
2. `DEEPGRAM_API_KEY` is set
3. Voice ID is valid (e.g., `aura-asteria-en`)

**Fix:**
```bash
# Test Deepgram connection
curl https://api.deepgram.com/v1/speak \
  -H "Authorization: Token YOUR_DEEPGRAM_KEY" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world"}' \
  --output test.mp3
```

### GPT-4o-mini Not Being Used

**Symptom:** Slow responses (>2 seconds for LLM)

**Check logs for:**
```
Requesting streaming chat completion { model: 'gpt-4o-mini' }
```

**Fix:**
```bash
# Update agent config
# Make sure llm.model is set to 'gpt-4o-mini'
```

---

## Performance Monitoring

### Real-Time Monitoring

```bash
# Watch latency metrics
tail -f logs/combined.log | grep -E "SILENCE|STREAMING|duration"

# Count optimizations in use
grep -c "v4" logs/combined.log
```

### Key Metrics

Track these in your monitoring dashboard:

1. **End-to-End Latency:**
   - Target: <3 seconds
   - Measure: User stops speaking â†’ AI starts speaking

2. **TTS TTFB:**
   - Target: <200ms
   - Look for: `âš¡ First audio byte (v2)`

3. **LLM Response Time:**
   - Target: <1.5 seconds
   - Look for: `duration` in chat completion logs

4. **Cost Per Call:**
   - Target: <$0.05 (down from $0.10)
   - Track in your billing dashboard

---

## Cost Analysis

### Before V4 (GPT-4)
```
5-minute call:
- STT (Deepgram): $0.022
- LLM (GPT-4): $0.045
- TTS (Deepgram): $0.0002
- Telephony: $0.03
Total: ~$0.10 per call
```

### After V4 (GPT-4o-mini)
```
5-minute call:
- STT (Deepgram): $0.022
- LLM (GPT-4o-mini): $0.002  âš¡ 95% reduction!
- TTS (Deepgram): $0.0002
- Telephony: $0.03
Total: ~$0.05 per call

Savings: $0.05 per call (50% reduction!)
```

**Monthly Impact (1000 calls):**
- Before: $100/month
- After: $50/month
- **Savings: $50/month or $600/year**

---

## Rollback

If you need to revert to V3:

### Quick Rollback
```bash
# 1. Update agents to use GPT-4
# Via MongoDB
mongo ai-calling
db.agents.updateMany(
  {},
  { $set: { "config.llm.model": "gpt-4" } }
)

# 2. Disable VAD (comment out in code)
# Edit: backend/src/websocket/handlers/exotelVoice.handler.ts
# Comment lines 326-344 (VAD check)

# 3. Disable streaming TTS (optional)
# Edit: backend/src/websocket/handlers/exotelVoice.handler.ts
# Replace streamTTSToExotel with sendPCMAudioToExotel

# 4. Restart
npm run dev
```

### Gradual Rollback
```bash
# Test on one agent first
curl -X PUT http://localhost:5000/api/v1/agents/{test-agent-id} \
  -d '{ "config": { "llm": { "model": "gpt-4" } } }'

# Monitor performance
# Rollback others if issues persist
```

---

## Best Practices

### 1. Phone-Optimized Prompts

```typescript
// âœ… GOOD - Concise for phone
"You are a support agent. Keep responses to 2-3 short sentences.
Be conversational and ask follow-up questions."

// âŒ BAD - Too verbose for phone
"You are a highly advanced AI support agent with extensive knowledge...
You should provide detailed explanations, multiple options, and..."
```

### 2. Voice Provider Selection

```typescript
// âœ… BEST - Deepgram for streaming
provider: "deepgram"   // Sub-200ms TTFB, streaming

// âš ï¸ OK - OpenAI fallback
provider: "openai"     // 300-500ms, non-streaming

// âŒ SLOW - ElevenLabs (high quality but slow)
provider: "elevenlabs" // 800-1200ms
```

### 3. LLM Configuration

```typescript
// âœ… OPTIMAL for phone calls
{
  "model": "gpt-4o-mini",
  "temperature": 0.7,      // Natural but controlled
  "maxTokens": 300         // Safe limit, won't truncate mid-sentence
}

// âš ï¸ Too low - will truncate!
{
  "model": "gpt-4o-mini",
  "temperature": 0.7,
  "maxTokens": 150         // âŒ BAD: Cuts off responses mid-sentence
}

// âœ… Best approach: Control via system prompt, no maxTokens limit
{
  "model": "gpt-4o-mini",
  "temperature": 0.7
  // No maxTokens - let prompt control brevity naturally
}
```

**Important:** `maxTokens` is a hard cutoff. Setting it too low (e.g., 150) will truncate responses mid-sentence. Better to use the phone-optimized system prompt (already implemented in handler) to naturally encourage brief responses.

---

## Support

### Check Logs First
```bash
# Full logs
tail -f logs/combined.log

# Errors only
tail -f logs/error.log

# V4 optimizations
grep "v4" logs/combined.log
```

### Common Issues

1. **High Latency:** Check which step is slow
2. **Audio Quality:** Verify Deepgram voice ID
3. **False Triggers:** Adjust VAD threshold (line 331)
4. **Cost Too High:** Verify gpt-4o-mini is being used

### Get Help

- GitHub Issues: [Your repo]/issues
- Docs: See LATENCY_OPTIMIZATIONS_V4.md
- Logs: Share combined.log excerpt

---

## Next Steps

1. âœ… Deploy V4 to production
2. ðŸ“Š Monitor performance metrics
3. ðŸ’° Track cost savings
4. ðŸŽ¯ Fine-tune VAD threshold if needed
5. ðŸš€ Consider future optimizations (see LATENCY_OPTIMIZATIONS_V4.md)

---

**Questions?** Read the full documentation: [LATENCY_OPTIMIZATIONS_V4.md](./LATENCY_OPTIMIZATIONS_V4.md)

**Version:** 4.0
**Last Updated:** 2025-01-29
**Status:** âœ… Production Ready
